{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Language Model: flat data, without context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mostly-ai/mostlyai-engine/blob/main/examples/language.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-05 13:43:49,105] INFO   : TRAIN_LANGUAGE started\n",
      "[2025-02-05 13:43:49,115] INFO   : numpy=1.26.4, pandas=2.2.3\n",
      "[2025-02-05 13:43:49,118] INFO   : torch=2.5.1, opacus=1.5.2\n",
      "[2025-02-05 13:43:49,123] INFO   : transformers=4.46.3, peft=0.11.1\n",
      "[2025-02-05 13:43:49,124] INFO   : device=device(type='cpu')\n",
      "[2025-02-05 13:43:49,126] INFO   : bf16_supported=False\n",
      "[2025-02-05 13:43:49,126] INFO   : use_mixed_precision=False\n",
      "[2025-02-05 13:43:49,127] INFO   : model_id='MOSTLY_AI/LSTMFromScratch-3m'\n",
      "[2025-02-05 13:43:49,127] INFO   : enable_flexible_generation=True\n",
      "[2025-02-05 13:43:49,128] INFO   : max_training_time=12.0s\n",
      "[2025-02-05 13:43:49,128] INFO   : max_epochs=100.0\n",
      "[2025-02-05 13:43:49,129] INFO   : with_dp=False\n",
      "[2025-02-05 13:43:49,130] INFO   : model_state_strategy=<ModelStateStrategy.reset: 'RESET'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-05 13:44:01,027] INFO   : create training model\n",
      "[2025-02-05 13:44:01,031] INFO   : model weights not found; change strategy from ModelStateStrategy.reset to RESET\n",
      "[2025-02-05 13:44:01,032] INFO   : model_state_strategy=<ModelStateStrategy.reset: 'RESET'>\n",
      "[2025-02-05 13:44:01,033] INFO   : clear existing checkpoint files\n",
      "[2025-02-05 13:44:01,035] INFO   : start training progress from epoch=0.0, steps=0\n",
      "[2025-02-05 13:44:01,233] INFO   : model loading time: 0.20s\n",
      "[2025-02-05 13:44:01,234] INFO   : no_of_model_params=595591\n",
      "[2025-02-05 13:44:01,235] INFO   : no_of_trainable_model_params=595591\n",
      "[2025-02-05 13:44:01,235] INFO   : tokenizer=LlamaTokenizerFast(name_or_path='', vocab_size=135, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "[2025-02-05 13:44:01,992] INFO   : trn_cnt=20768, val_cnt=2308\n",
      "[2025-02-05 13:44:01,992] INFO   : trn_batch_size=64, val_batch_size=32\n",
      "[2025-02-05 13:44:01,993] INFO   : trn_steps=324, val_steps=72\n",
      "[2025-02-05 13:44:01,993] INFO   : batch_size=32, gradient_accumulation_steps=2, initial_lr=0.0004\n",
      "[2025-02-05 13:44:02,226] INFO   : {'epoch': 0.0, 'is_checkpoint': 0, 'steps': 1, 'samples': 64, 'trn_loss': None, 'val_loss': None, 'total_time': 0.2, 'learn_rate': 0.0004, 'dp_eps': None, 'dp_delta': None}\n",
      "[2025-02-05 13:44:14,525] INFO   : saving model weights, as none were saved so far\n",
      "[2025-02-05 13:44:15,834] INFO   : {'epoch': 0.46, 'is_checkpoint': 1, 'steps': 148, 'samples': 9472, 'trn_loss': None, 'val_loss': 0.2542, 'total_time': 13.8, 'learn_rate': 0.0004, 'dp_eps': None, 'dp_delta': None}\n",
      "[2025-02-05 13:44:15,842] INFO   : TRAIN_LANGUAGE finished in 26.74s\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from mostlyai import engine\n",
    "\n",
    "# init workspace and logging\n",
    "# ws = Path(\"ws-language-flat\")\n",
    "ws = Path(\"ws-language-categorical-flat\")\n",
    "engine.init_logging()\n",
    "\n",
    "# # load original data\n",
    "# url = \"https://github.com/mostly-ai/public-demo-data/raw/refs/heads/dev/arxiv\"\n",
    "# # trn_df = pd.read_parquet(f\"{url}/synthetic-data-papers.parquet\")[['category', 'title']]\n",
    "# trn_df = pd.read_parquet(f\"{url}/synthetic-data-papers.parquet\")[['category']]\n",
    "\n",
    "# execute the engine steps\n",
    "# engine.split(                         # split data as PQT files for `trn` + `val` to `{ws}/OriginalData/tgt-data`\n",
    "#     workspace_dir=ws,\n",
    "#     tgt_data=trn_df,\n",
    "#     # model_type=\"LANGUAGE\",\n",
    "#     tgt_encoding_types={\"category\": \"LANGUAGE_CATEGORICAL\"},\n",
    "# )\n",
    "# engine.analyze(workspace_dir=ws)      # generate column-level statistics to `{ws}/ModelStore/tgt-stats/stats.json`\n",
    "# engine.encode(workspace_dir=ws)       # encode training data to `{ws}/OriginalData/encoded-data`\n",
    "# engine.train(                         # train model and store to `{ws}/ModelStore/model-data`\n",
    "#     workspace_dir=ws,\n",
    "#     model=\"MOSTLY_AI/LSTMFromScratch-3m\",  # use a light-weight LSTM model, trained from scratch (GPU recommended)\n",
    "#     # model=\"microsoft/phi-1.5\",           # or alternatively use a HF-hosted LLM model (GPU required)\n",
    "#     max_training_time=0.2,                  # limit TRAIN to 10 minute for demo purposes\n",
    "# )\n",
    "engine.generate(                      # use model to generate synthetic samples to `{ws}/SyntheticData`\n",
    "    workspace_dir=ws, \n",
    "    sample_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_tgt_df = pd.read_parquet(ws / \"SyntheticData\") # load synthetic data\n",
    "syn_tgt_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
