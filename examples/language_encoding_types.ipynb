{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Language Model: flat data, without context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mostly-ai/mostlyai-engine/blob/main/examples/language.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T13:52:43.092585Z",
     "iopub.status.busy": "2025-02-05T13:52:43.092035Z",
     "iopub.status.idle": "2025-02-05T13:56:20.259209Z",
     "shell.execute_reply": "2025-02-05T13:56:20.258849Z",
     "shell.execute_reply.started": "2025-02-05T13:52:43.092556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-05 14:52:45,343] INFO   : SPLIT started\n",
      "[2025-02-05 14:52:45,344] INFO   : clean `ws-language-categorical-flat/OriginalData/tgt-data`\n",
      "[2025-02-05 14:52:45,345] INFO   : clean `ws-language-categorical-flat/OriginalData/tgt-meta`\n",
      "[2025-02-05 14:52:45,346] INFO   : model_type='LANGUAGE'\n",
      "[2025-02-05 14:52:45,346] INFO   : tgt_encoding_types={'category': 'LANGUAGE_CATEGORICAL', 'title': 'LANGUAGE_TEXT'}\n",
      "[2025-02-05 14:52:45,360] INFO   : SPLIT finished in 0.02s\n",
      "[2025-02-05 14:52:45,361] INFO   : ANALYZE started\n",
      "[2025-02-05 14:52:45,363] INFO   : clean `ws-language-categorical-flat/ModelStore/tgt-stats`\n",
      "[2025-02-05 14:52:45,364] INFO   : analyzing 2 partitions in parallel\n",
      "[2025-02-05 14:52:45,413] INFO   : analyzed target partition 000000-trn (20768, 2)\n",
      "[2025-02-05 14:52:45,422] INFO   : analyzed target partition 000000-val (2308, 2)\n",
      "[2025-02-05 14:52:45,422] INFO   : combine partition statistics\n",
      "[2025-02-05 14:52:45,423] INFO   : analyzed column `category`: LANGUAGE_CATEGORICAL \n",
      "[2025-02-05 14:52:45,423] INFO   : analyzed column `title`: LANGUAGE_TEXT \n",
      "[2025-02-05 14:52:45,424] INFO   : analyzed 23,076 records: 20,768 training / 2,308 validation\n",
      "[2025-02-05 14:52:45,425] INFO   : tgt sequence length deciles: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[2025-02-05 14:52:45,425] INFO   : is_sequential: False\n",
      "[2025-02-05 14:52:45,425] INFO   : write statistics to `ws-language-categorical-flat/ModelStore/tgt-stats/stats.json`\n",
      "[2025-02-05 14:52:45,426] INFO   : ANALYZE finished in 0.06s\n",
      "[2025-02-05 14:52:45,427] INFO   : ENCODE_LANGUAGE started\n",
      "[2025-02-05 14:52:45,428] INFO   : clean `ws-language-categorical-flat/OriginalData/encoded-data`\n",
      "[2025-02-05 14:52:45,428] INFO   : clean `ws-language-categorical-flat/OriginalData/encoded-data`\n",
      "[2025-02-05 14:52:45,429] INFO   : clean `ws-language-categorical-flat/OriginalData/encoded-data`\n",
      "[2025-02-05 14:52:45,434] INFO   : Formatting context columns [] to JSON\n",
      "[2025-02-05 14:52:45,443] INFO   : Formatting target columns ['category', 'title'] to JSON\n",
      "[2025-02-05 14:52:46,161] INFO   : token statistics of this partition: \n",
      "     #pretokens  #chars\n",
      "min        16.0    50.0\n",
      "50%        27.0   115.0\n",
      "max        67.0   208.0\n",
      "[2025-02-05 14:52:46,172] INFO   : encoded partition part.000000-trn.parquet (20768, 2)\n",
      "[2025-02-05 14:52:46,177] INFO   : Formatting context columns [] to JSON\n",
      "[2025-02-05 14:52:46,181] INFO   : Formatting target columns ['category', 'title'] to JSON\n",
      "[2025-02-05 14:52:46,289] INFO   : token statistics of this partition: \n",
      "     #pretokens  #chars\n",
      "min        16.0    52.0\n",
      "50%        27.0   115.0\n",
      "max        52.0   199.0\n",
      "[2025-02-05 14:52:46,292] INFO   : encoded partition part.000000-val.parquet (2308, 2)\n",
      "[2025-02-05 14:52:46,292] INFO   : ENCODE_LANGUAGE finished in 0.87s\n",
      "[2025-02-05 14:52:46,293] INFO   : TRAIN_LANGUAGE started\n",
      "[2025-02-05 14:52:46,303] INFO   : numpy=1.26.4, pandas=2.2.3\n",
      "[2025-02-05 14:52:46,305] INFO   : torch=2.5.1, opacus=1.5.2\n",
      "[2025-02-05 14:52:46,309] INFO   : transformers=4.46.3, peft=0.11.1\n",
      "[2025-02-05 14:52:46,309] INFO   : device=device(type='cpu')\n",
      "[2025-02-05 14:52:46,309] INFO   : bf16_supported=False\n",
      "[2025-02-05 14:52:46,310] INFO   : use_mixed_precision=False\n",
      "[2025-02-05 14:52:46,310] INFO   : model_id='MOSTLY_AI/LSTMFromScratch-3m'\n",
      "[2025-02-05 14:52:46,310] INFO   : enable_flexible_generation=True\n",
      "[2025-02-05 14:52:46,310] INFO   : max_training_time=60s\n",
      "[2025-02-05 14:52:46,311] INFO   : max_epochs=100.0\n",
      "[2025-02-05 14:52:46,311] INFO   : with_dp=False\n",
      "[2025-02-05 14:52:46,311] INFO   : model_state_strategy=<ModelStateStrategy.reset: 'RESET'>\n",
      "[2025-02-05 14:52:52,892] INFO   : create training model\n",
      "[2025-02-05 14:52:52,893] INFO   : model_state_strategy=<ModelStateStrategy.reset: 'RESET'>\n",
      "[2025-02-05 14:52:52,893] INFO   : clear existing checkpoint files\n",
      "[2025-02-05 14:52:52,895] INFO   : start training progress from epoch=0.0, steps=0\n",
      "[2025-02-05 14:52:53,274] INFO   : model loading time: 0.38s\n",
      "[2025-02-05 14:52:53,274] INFO   : no_of_model_params=2668111\n",
      "[2025-02-05 14:52:53,274] INFO   : no_of_trainable_model_params=2668111\n",
      "[2025-02-05 14:52:53,275] INFO   : tokenizer=LlamaTokenizerFast(name_or_path='', vocab_size=4175, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "[2025-02-05 14:52:54,202] INFO   : trn_cnt=20768, val_cnt=2308\n",
      "[2025-02-05 14:52:54,202] INFO   : trn_batch_size=64, val_batch_size=32\n",
      "[2025-02-05 14:52:54,203] INFO   : trn_steps=324, val_steps=72\n",
      "[2025-02-05 14:52:54,203] INFO   : batch_size=32, gradient_accumulation_steps=2, initial_lr=0.0004\n",
      "[2025-02-05 14:52:54,677] INFO   : {'epoch': 0.0, 'is_checkpoint': 0, 'steps': 1, 'samples': 64, 'trn_loss': None, 'val_loss': None, 'total_time': 0.5, 'learn_rate': 0.0004, 'dp_eps': None, 'dp_delta': None}\n",
      "[2025-02-05 14:53:54,325] INFO   : saving model weights, as none were saved so far\n",
      "[2025-02-05 14:53:57,632] INFO   : {'epoch': 0.63, 'is_checkpoint': 1, 'steps': 205, 'samples': 13120, 'trn_loss': None, 'val_loss': 2.9262, 'total_time': 63.4, 'learn_rate': 0.0004, 'dp_eps': None, 'dp_delta': None}\n",
      "[2025-02-05 14:53:57,634] INFO   : TRAIN_LANGUAGE finished in 71.34s\n",
      "[2025-02-05 14:53:57,643] INFO   : GENERATE_LANGUAGE started\n",
      "[2025-02-05 14:53:57,643] INFO   : device=device(type='cpu')\n",
      "[2025-02-05 14:53:57,644] INFO   : sampling_temperature=1.0, sampling_top_p=1.0\n",
      "[2025-02-05 14:53:57,644] INFO   : clean `ws-language-categorical-flat/SyntheticData`\n",
      "[2025-02-05 14:53:57,649] INFO   : seed_data.shape=(10000, 0)\n",
      "[2025-02-05 14:53:57,650] INFO   : Formatting context columns [] to JSON\n",
      "[2025-02-05 14:53:57,674] INFO   : token statistics of this partition: \n",
      "     #pretokens  #chars\n",
      "min         1.0     3.0\n",
      "50%         1.0     3.0\n",
      "max         1.0     3.0\n",
      "[2025-02-05 14:53:57,675] INFO   : max_new_tokens=151\n",
      "[2025-02-05 14:53:57,774] INFO   : inference engine: HuggingFaceEngine\n",
      "[2025-02-05 14:53:57,774] INFO   : model loading time: 0.10s\n",
      "[2025-02-05 14:53:57,775] INFO   : batch_size=128\n",
      "[2025-02-05 14:53:57,775] INFO   : enforce_json_output=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/05/2025 14:53:57:WARNING:The following bytes are not present in any token: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247]. This likely indicates that the vocabulary loading code is wrong, the tokenizer is doing some creepy processing or the tokenizer is not UTF-8 compatible. Check the vocabulary loading code and the tokenizer code to fix any bug and/or consider processing the vocab like the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-05 14:56:20,197] INFO   : num_samples_max_length_limit=0\n",
      "[2025-02-05 14:56:20,241] INFO   : percentage of invalid values: {'category': '0.00%', 'title': '0.00%'}\n",
      "[2025-02-05 14:56:20,241] INFO   : decoded (10000, 2) from 79 batches in 1.30s\n",
      "[2025-02-05 14:56:20,244] INFO   : persisted (10000, 2) to `part.000000.000000.parquet` in 0.00s\n",
      "[2025-02-05 14:56:20,246] INFO   : total_tokenize_fn_time=0.21s\n",
      "[2025-02-05 14:56:20,246] INFO   : total_logits_processor_build_time=1.37s\n",
      "[2025-02-05 14:56:20,246] INFO   : total_generate_fn_time=139.43s\n",
      "[2025-02-05 14:56:20,246] INFO   : GENERATE_LANGUAGE finished in 142.60s\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from mostlyai import engine\n",
    "\n",
    "# init workspace and logging\n",
    "# ws = Path(\"ws-language-flat\")\n",
    "ws = Path(\"ws-language-categorical-flat\")\n",
    "engine.init_logging()\n",
    "\n",
    "# # load original data\n",
    "url = \"https://github.com/mostly-ai/public-demo-data/raw/refs/heads/dev/arxiv\"\n",
    "trn_df = pd.read_parquet(f\"{url}/synthetic-data-papers.parquet\")[['category', 'title']]\n",
    "# trn_df = pd.read_parquet(f\"{url}/synthetic-data-papers.parquet\")[['category']]\n",
    "\n",
    "# execute the engine steps\n",
    "engine.split(                         # split data as PQT files for `trn` + `val` to `{ws}/OriginalData/tgt-data`\n",
    "    workspace_dir=ws,\n",
    "    tgt_data=trn_df,\n",
    "    # model_type=\"LANGUAGE\",\n",
    "    tgt_encoding_types={\"category\": \"LANGUAGE_CATEGORICAL\", \"title\": \"LANGUAGE_TEXT\"},\n",
    ")\n",
    "engine.analyze(workspace_dir=ws)      # generate column-level statistics to `{ws}/ModelStore/tgt-stats/stats.json`\n",
    "engine.encode(workspace_dir=ws)       # encode training data to `{ws}/OriginalData/encoded-data`\n",
    "engine.train(                         # train model and store to `{ws}/ModelStore/model-data`\n",
    "    workspace_dir=ws,\n",
    "    model=\"MOSTLY_AI/LSTMFromScratch-3m\",  # use a light-weight LSTM model, trained from scratch (GPU recommended)\n",
    "    # model=\"microsoft/phi-1.5\",           # or alternatively use a HF-hosted LLM model (GPU required)\n",
    "    max_training_time=1,                   # limit TRAIN to 10 minute for demo purposes\n",
    ")\n",
    "engine.generate(                      # use model to generate synthetic samples to `{ws}/SyntheticData`\n",
    "    workspace_dir=ws, \n",
    "    sample_size=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T13:56:20.260268Z",
     "iopub.status.busy": "2025-02-05T13:56:20.260149Z",
     "iopub.status.idle": "2025-02-05T13:56:20.269394Z",
     "shell.execute_reply": "2025-02-05T13:56:20.268803Z",
     "shell.execute_reply.started": "2025-02-05T13:56:20.260257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chao-dyn',\n",
       " 'cmp-lg',\n",
       " 'comp-gas',\n",
       " 'cond-mat.other',\n",
       " 'cond-mat.quant-gas',\n",
       " 'cond-mat.supr-con',\n",
       " 'cs.CC',\n",
       " 'cs.DL',\n",
       " 'cs.FL',\n",
       " 'cs.OS',\n",
       " 'cs.PL',\n",
       " 'cs.SC',\n",
       " 'econ.TH',\n",
       " 'math.CA',\n",
       " 'math.CT',\n",
       " 'math.DG',\n",
       " 'math.FA',\n",
       " 'math.GM',\n",
       " 'math.GN',\n",
       " 'math.GR',\n",
       " 'math.MG',\n",
       " 'math.SP',\n",
       " 'nlin.AO',\n",
       " 'nucl-ex',\n",
       " 'nucl-th',\n",
       " 'q-bio.CB',\n",
       " 'q-bio.OT',\n",
       " 'q-bio.SC',\n",
       " 'q-fin.EC',\n",
       " 'q-fin.MF',\n",
       " 'q-fin.PR'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_tgt_df = pd.read_parquet(ws / \"SyntheticData\") # load synthetic data\n",
    "set(trn_df['category']) - set(syn_tgt_df['category']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T13:56:20.270196Z",
     "iopub.status.busy": "2025-02-05T13:56:20.270014Z",
     "iopub.status.idle": "2025-02-05T13:56:20.279656Z",
     "shell.execute_reply": "2025-02-05T13:56:20.278913Z",
     "shell.execute_reply.started": "2025-02-05T13:56:20.270181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_RARE_'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(syn_tgt_df['category']) - set(trn_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T13:56:20.282741Z",
     "iopub.status.busy": "2025-02-05T13:56:20.281808Z",
     "iopub.status.idle": "2025-02-05T13:56:20.288184Z",
     "shell.execute_reply": "2025-02-05T13:56:20.287499Z",
     "shell.execute_reply.started": "2025-02-05T13:56:20.282643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             , \n",
       "1                                       category\n",
       "2                                      : A- for \n",
       "3                                             : \n",
       "4                                          ,  to\n",
       "5                                          -..ML\n",
       "6                                          D the\n",
       "7    -Oed Learning with-to for-c- and Data ofe\n",
       " \n",
       "8          S from: a Learning ofn- for Synthetic\n",
       "9                                               \n",
       "Name: title, dtype: string"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_tgt_df['title'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T13:56:20.289566Z",
     "iopub.status.busy": "2025-02-05T13:56:20.289133Z",
     "iopub.status.idle": "2025-02-05T13:56:20.296014Z",
     "shell.execute_reply": "2025-02-05T13:56:20.295608Z",
     "shell.execute_reply.started": "2025-02-05T13:56:20.289552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Conception d'un banc d'essais d\\'ecisionnel\n",
       "1         Monotonicity Analysis over Chains and Curves\n",
       "2    An active curve approach for tomographic recon...\n",
       "3    Application of the HLSVD technique to the filt...\n",
       "4              Phase retrieval by iterated projections\n",
       "5               DIRC for a Higher Luminosity B Factory\n",
       "6    Analysis of approximate nearest neighbor searc...\n",
       "7    Efficient Retrieval of Similar Time Sequences ...\n",
       "8    Mining Generalized Graph Patterns based on Use...\n",
       "9    ARACNE: An Algorithm for the Reconstruction of...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df['title'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T13:56:20.296770Z",
     "iopub.status.busy": "2025-02-05T13:56:20.296615Z",
     "iopub.status.idle": "2025-02-05T13:56:20.302894Z",
     "shell.execute_reply": "2025-02-05T13:56:20.302345Z",
     "shell.execute_reply.started": "2025-02-05T13:56:20.296758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs.CV</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs.CY</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stat.ML</td>\n",
       "      <td>: A- for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cs.CV</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs.LG</td>\n",
       "      <td>,  to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>cs.LG</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>stat.ME</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>cs.LG</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>cs.CL</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>stat.ML</td>\n",
       "      <td>C.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category      title\n",
       "0       cs.CV         , \n",
       "1       cs.CY   category\n",
       "2     stat.ML  : A- for \n",
       "3       cs.CV         : \n",
       "4       cs.LG      ,  to\n",
       "...       ...        ...\n",
       "9995    cs.LG   category\n",
       "9996  stat.ME         : \n",
       "9997    cs.LG         D \n",
       "9998    cs.CL         : \n",
       "9999  stat.ML         C.\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_tgt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
