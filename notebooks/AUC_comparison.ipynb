{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c79a6a2-f93d-406b-9b1e-08a99b7fc965",
   "metadata": {},
   "source": [
    "# mostly.classify vs AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b242b0-30d4-4dec-94d2-6ad139693d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivona/git/mostlyai-engine/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mostlyai import engine\n",
    "from mostlyai.engine.domain import ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189b4bf1-ff82-4a27-9275-9b3713506e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ebcafd7-a963-43e7-ba16-2af0b2eeceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_652103/1846604647.py:9: FutureWarning:\n",
      "\n",
      "Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path(\"..\").resolve()\n",
    "DATA = \"census.csv.gz\"\n",
    "DATA_PATH = ROOT / \"data\" / DATA\n",
    "TARGET = \"income\"\n",
    "POS_LABEL = 1\n",
    "ws = ROOT / f\"ws-{DATA}-classify\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df.replace({\"<=50K\": 0, \">50K\": 1})\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b137d8d-43ad-495e-8883-41263590309d",
   "metadata": {},
   "source": [
    "## AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3788c53c-86f9-4a44-8c93-9d7f816d2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== CONFIG ======\n",
    "SAVE_DIR = \"ag_models_fast\"\n",
    "MODELS_TO_RUN = [\"GBM\", \"XGB\"]  # fast + strong\n",
    "TIME_LIMIT = 300  # seconds total budget\n",
    "EVAL_METRIC = \"roc_auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73454907-0bac-41a5-90bb-f4cd92cb5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_autogluon(train_df, test_df):\n",
    "    train_data = TabularDataset(train_df)\n",
    "    test_data = TabularDataset(test_df)\n",
    "\n",
    "    # ====== TRAIN (only selected models, no bagging/stacking) ======\n",
    "    hyperparameters = {m: {} for m in MODELS_TO_RUN}\n",
    "    predictor = TabularPredictor(\n",
    "        label=TARGET,\n",
    "        path=SAVE_DIR,\n",
    "        eval_metric=EVAL_METRIC,\n",
    "    ).fit(\n",
    "        train_data=train_data,\n",
    "        time_limit=TIME_LIMIT,\n",
    "        hyperparameters=hyperparameters,\n",
    "    )\n",
    "\n",
    "    # ====== PICK WINNER (by validation AUC) ======\n",
    "    lb = predictor.leaderboard(silent=True)\n",
    "    # AutoGluon 'score_val' aligns with eval_metric: higher is better for roc_auc\n",
    "    best_model = lb.sort_values(\"score_val\", ascending=False)[\"model\"].iloc[0]\n",
    "    #     print(f\"Best model: {best_model}\")\n",
    "\n",
    "    # ====== PREDICT PROBABILITIES ON TEST WITH THE WINNER ======\n",
    "    proba = predictor.predict_proba(test_data, model=best_model, as_pandas=True)\n",
    "\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f2cab0-8e70-4cc4-a0e3-defb672bf8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_models_fast\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.16\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #32~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Sep  2 14:21:04 UTC 2\n",
      "CPU Count:          12\n",
      "Memory Avail:       7.74 GB / 30.95 GB (25.0%)\n",
      "Disk Space Avail:   7.07 GB / 465.36 GB (1.5%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"/home/ivona/git/mostlyai-engine/notebooks/ag_models_fast\"\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column:       income\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7956.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 21.55 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital_status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital_status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.09 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0639828014229775, Train Rows: 36573, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{}],\n",
      "\t'XGB': [{}],\n",
      "}\n",
      "Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM ... Training model for up to 299.76s of the 299.76s of remaining time.\n",
      "\tFitting with cpus=6, gpus=0, mem=0.0/7.8 GB\n",
      "\t0.9293\t = Validation score   (roc_auc)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 298.68s of the 298.67s of remaining time.\n",
      "\tFitting with cpus=6, gpus=0\n",
      "\t0.9295\t = Validation score   (roc_auc)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 297.94s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost': 0.579, 'LightGBM': 0.421}\n",
      "\t0.9304\t = Validation score   (roc_auc)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.12s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 81913.0 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/ivona/git/mostlyai-engine/notebooks/ag_models_fast\")\n"
     ]
    }
   ],
   "source": [
    "proba_ag = run_autogluon(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067babf-7030-4752-9cdf-f45ea43aa9bf",
   "metadata": {},
   "source": [
    "## MOSTLY engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "859152eb-82a9-40eb-b581-96fa19abc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c != TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123968b-845a-415f-956f-da00c5f36db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the generator\n",
    "engine.split(workspace_dir=ws, tgt_data=train_df, model_type=ModelType.tabular)\n",
    "engine.analyze(workspace_dir=ws)\n",
    "engine.encode(workspace_dir=ws)\n",
    "engine.train(workspace_dir=ws, enable_flexible_generation=True)\n",
    "# # Generate synthetic data (for comparison)\n",
    "engine.generate(workspace_dir=ws, sample_size=len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8679b-836d-46f8-afbc-bdb6a92979ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify TARGET using all other columns as features\n",
    "proba_df = engine.classify(data=test_df, features=features, target=TARGET, workspace_dir=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72035008-d422-44b7-8623-0ce7a2f670ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it was necessary to adjust dtypes for Autogluon\n",
    "syn = pd.read_parquet(os.path.join(ws, \"SyntheticData\"))\n",
    "syn = syn.astype(train_df.dtypes.to_dict(), errors=\"ignore\")\n",
    "proba_syn_ag = run_autogluon(syn, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ac84e-6381-47dd-a643-8fa31fe1e804",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d79e2-ec48-4c83-9751-600710e6bb48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "approaches = {\n",
    "    \"original_AG\": proba_ag[1].values,\n",
    "    \"syn_AG\": proba_syn_ag[1].values,\n",
    "    \"probs\": proba_df[\"proba_1\"].values,\n",
    "}\n",
    "# True labels\n",
    "y_true = test_df[TARGET].values\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "for name, y_score in approaches.items():\n",
    "    # auc = evaluate_auc(y_true, y_score, POS_LABEL)\n",
    "    auc = roc_auc_score(y_true, y_score)\n",
    "    results.append({\"approach\": name, \"auc\": auc})\n",
    "\n",
    "# Convert to summary DataFrame\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba5911-0213-41f9-96f5-f46f403ad3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    summary_df,\n",
    "    y=\"approach\",\n",
    "    x=\"auc\",\n",
    "    orientation=\"h\",\n",
    "    text=\"auc\",  # show AUC value on bars\n",
    "    title=\"AUC by Approach\",\n",
    "    labels={\"approach\": \"Approach\", \"auc\": \"AUC\"},\n",
    "    color=\"approach\",\n",
    ")\n",
    "min_auc = summary_df[\"auc\"].min()\n",
    "max_auc = summary_df[\"auc\"].max()\n",
    "margin = (max_auc - min_auc) * 0.1  # add 10% margin\n",
    "fig.update_xaxes(range=[min_auc - margin, max_auc + margin])\n",
    "fig.update_traces(texttemplate=\"%{text:.4f}\", textposition=\"outside\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a690b-2cf2-4959-ad46-fadbc60e42c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mostlyai-venv)",
   "language": "python",
   "name": "mostlyai-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
